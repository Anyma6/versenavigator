name: Check for duplicate domains in links

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  check_links:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Recupera tutto il repository, inclusi i rami remoti

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Extract links from pull request
        run: |
          git fetch origin main  # Assicura che il branch main sia disponibile
          git diff origin/main... > pr_links.txt

      - name: Run duplicate domain checker
        id: check_links
        run: |
          python check_links.py > check_links_output.txt || echo "exit_code=1" >> $GITHUB_ENV
        continue-on-error: true

      - name: Check for duplicate domains
        id: parse_output
        run: |
          if grep -q "DUPLICATE_DOMAINS" check_links_output.txt; then
            echo "duplicate_domains=$(cat check_links_output.txt | grep -A1000 'DUPLICATE_DOMAINS' | tail -n +2)" >> $GITHUB_ENV
          fi

      - name: Comment on pull request with warning if duplicates found
        if: env.exit_code == '1'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          duplicate_domains="${{ env.duplicate_domains }}"
          curl -X POST -H "Authorization: token $GITHUB_TOKEN" \
          -H "Content-Type: application/json" \
          -d "{\"body\": \"⚠️ Potential duplicate domain(s) found in the PR:\n${duplicate_domains}\nPlease make sure these resources are not already listed. If this is an error, please open an issue linking this PR.\"}" \
          "${{ github.event.pull_request.url }}/comments"
