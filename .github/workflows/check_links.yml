name: Check for duplicate domains in links

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  check_links:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Recupera tutto il repository, inclusi i rami remoti

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Extract links from pull request
        run: |
          git fetch origin main  # Assicura che il branch main sia disponibile
          git diff origin/main... > pr_links.txt

      - name: Run duplicate domain checker
        id: check_links
        run: |
          output=$(python check_links.py) || exit_code=$?
          echo "$output"
          echo "$output" | grep -q "DUPLICATE_DOMAINS" && echo "duplicate_domains=${output}" >> $GITHUB_ENV
          exit $exit_code || 0  # Imposta un'uscita senza errore se duplicati sono stati trovati

      - name: Comment on pull request with warning if duplicates found
        if: env.duplicate_domains
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          curl -X POST -H "Authorization: token $GITHUB_TOKEN" \
          -H "Content-Type: application/json" \
          -d "{\"body\": \"⚠️ Potential duplicate domain(s) found in the PR:\n${{ env.duplicate_domains }}\nPlease make sure these resources are not already listed. If this is an error, please open an issue linking this PR.\"}" \
          "${{ github.event.pull_request.url }}/comments"
